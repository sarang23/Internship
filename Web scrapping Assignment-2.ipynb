{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------Web Scrapping  Assignement -2------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Selenium \n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all required libraries \n",
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# Opening Browsers in Incognito using Options\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data from Naukri.com\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding Element for Job Search.\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on Search Button\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of webpage to be scraped\n",
    "url=\"https://www.naukri.com/data-analyst-jobs-in-banglore?k=data%20analyst&l=banglore\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create 3 empty list for our requirment as Job title, Location and Company name \n",
    "\n",
    "job_titles=[]\n",
    "company_name=[]\n",
    "location_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can extract all the title tags haiving job titles and we have to find first 10 job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "job_titles[0:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can extract all the title tags haiving job titles and we have to find first 10 companies Name\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in companies_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can extract all the title tags haiving job titles and we have to find first 10 Location List\n",
    "location_tags=driver.find_elements_by_xpath(\".//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    location_list.append(location)\n",
    "location_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the length of lists\n",
    "print(len(location_list),len(company_name),len(job_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Super India Tech Mark</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CONDUENT BUSINESS SERVICES INDIA LLP</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Concentrix Daksh Services India Private Limited.</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cerner Corporation</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INTERTRUST GROUP</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Happy Marketer Private Ltd</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Optimize Overseas LLC</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LatentView Analytics Private Limited</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Title                                      Company Name  \\\n",
       "0     NaN                             Super India Tech Mark   \n",
       "1     NaN                                 tech mahindra ltd   \n",
       "2     NaN              CONDUENT BUSINESS SERVICES INDIA LLP   \n",
       "3     NaN           GlaxoSmithKline Pharmaceuticals Limited   \n",
       "4     NaN                          Myntra Designs Pvt. Ltd.   \n",
       "5     NaN                          Myntra Designs Pvt. Ltd.   \n",
       "6     NaN  Concentrix Daksh Services India Private Limited.   \n",
       "7     NaN                                            Cerner   \n",
       "8     NaN                                Cerner Corporation   \n",
       "9     NaN                 Flipkart Internet Private Limited   \n",
       "10    NaN                             Philips India Limited   \n",
       "11    NaN                        Capco Technologies Pvt Ltd   \n",
       "12    NaN                     GENPACT India Private Limited   \n",
       "13    NaN                                  INTERTRUST GROUP   \n",
       "14    NaN                        Happy Marketer Private Ltd   \n",
       "15    NaN                                      Diverse Lynx   \n",
       "16    NaN                          Myntra Designs Pvt. Ltd.   \n",
       "17    NaN                             Optimize Overseas LLC   \n",
       "18    NaN              LatentView Analytics Private Limited   \n",
       "19    NaN                                      Walmart Labs   \n",
       "\n",
       "                                        Location Name  \n",
       "0                      Bangalore/Bengaluru(Devalapur)  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3                                 Bangalore/Bengaluru  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                                 Bangalore/Bengaluru  \n",
       "6   Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8                                 Bangalore/Bengaluru  \n",
       "9                                 Bangalore/Bengaluru  \n",
       "10                                Bangalore/Bengaluru  \n",
       "11                          Pune, Bangalore/Bengaluru  \n",
       "12                                Bangalore/Bengaluru  \n",
       "13                        Mumbai, Bangalore/Bengaluru  \n",
       "14            Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "15                                Bangalore/Bengaluru  \n",
       "16                                Bangalore/Bengaluru  \n",
       "17          Kolkata, Bangalore/Bengaluru, Delhi / NCR  \n",
       "18                       Chennai, Bangalore/Bengaluru  \n",
       "19                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we will make a data frame\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Company Name']=company_name\n",
    "jobs['Location Name']=location_list\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function opens the naukri home page and searches for 'Data Scientist' and 'Bangalore'\n",
    "\n",
    "def naukri_desc(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "\n",
    "    # 2. Enter “Data Scientist” in “Skill,Designations,Companies” field\n",
    "\n",
    "    from selenium.common.exceptions import NoSuchElementException\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "        job_search.send_keys(\"Data Scientist\")\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"Exception Raised : \", e)\n",
    "\n",
    "    # and enter “Bangalore” in “enter the location” field \n",
    "    location_search=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    location_search.send_keys(\"Bangalore\")\n",
    "\n",
    "    # 3. Then click the search button\n",
    "    search_buton=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_buton.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    jobs=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "\n",
    "    job_titles=[]\n",
    "    company_names=[]\n",
    "    desc=[]\n",
    "\n",
    "    from selenium.common.exceptions import NoSuchElementException         # Importing Exception\n",
    "\n",
    "    for b in jobs:\n",
    "        url=b.get_attribute('href')\n",
    "        driver_1=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        driver_1.get(url)\n",
    "        try:\n",
    "            i=driver_1.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "            j=driver_1.find_element_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "            k=driver_1.find_elements_by_xpath(\"//div[@class='dang-inner-html']\")\n",
    "        except NoSuchElementException as e:\n",
    "            i=driver_1.find_element_by_xpath(\"//h1[@class='av-special-heading-tag ']\")\n",
    "            j=driver_1.find_element_by_xpath(\"//p[@class='cpName f14']\")\n",
    "            k=driver_1.find_elements_by_xpath(\"//div[@class='clearboth description']\")\n",
    "\n",
    "\n",
    "        job_titles.append(i.text)\n",
    "        company_names.append(j.text)        \n",
    "        # Collecting full description\n",
    "        desc_content=[]\n",
    "        for a in k:\n",
    "            desc_content.append(j.text.replace('\\n',' '))\n",
    "        desc.append(desc_content)\n",
    "\n",
    "        driver_1.close()\n",
    "    \n",
    "    jobs_2=pd.DataFrame({})\n",
    "    jobs_2['job_titles']=job_titles\n",
    "    jobs_2['company_names']=company_names\n",
    "    jobs_2['Full Job Description']=desc\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>Full Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>[Responsibilities and Duties Create innovative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>[Location - Bangalore / Bengaluru Duration- 6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Analyst</td>\n",
       "      <td>Becton Dickinson India Pvt. Ltd</td>\n",
       "      <td>[Roles and Responsibilities ob Description Sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>[Roles and Responsibilities   - Selecting feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>[Job description Job Summary and Key Responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>[About Ganit Inc  Founded by senior industry e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>[Roles and Responsibilities  Must have strong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GLOBAL MEDICAL DATA SCIENTIST</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>[This is an ideal role for an experienced cand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>[The Role General Position Definition This rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DATA SCIENTIST – ADVANCED ANALYTICS</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>[Introduction As a Data Scientist at IBM, you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0                                     Data Scientist   \n",
       "1  Opportunity For Data Scientist Internship - Be...   \n",
       "2                            Data Scientist/ Analyst   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4     Data Scientist || Data Analyst || Data science   \n",
       "5               Data Scientist/Senior Data Scientist   \n",
       "6  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "7                      GLOBAL MEDICAL DATA SCIENTIST   \n",
       "8           Associate Data Scientist - CRM & Loyalty   \n",
       "9                DATA SCIENTIST – ADVANCED ANALYTICS   \n",
       "\n",
       "                                company_names  \\\n",
       "0       CronJ IT Technologies Private Limited   \n",
       "1                      Corner Stone Solutions   \n",
       "2             Becton Dickinson India Pvt. Ltd   \n",
       "3                                 AugmatrixGo   \n",
       "4  Inspiration Manpower Consultancy Pvt. Ltd.   \n",
       "5    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "6                                    CES Ltd.   \n",
       "7     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8         Shell India Markets Private Limited   \n",
       "9                      IBM India Pvt. Limited   \n",
       "\n",
       "                                Full Job Description  \n",
       "0  [Responsibilities and Duties Create innovative...  \n",
       "1  [Location - Bangalore / Bengaluru Duration- 6 ...  \n",
       "2  [Roles and Responsibilities ob Description Sum...  \n",
       "3  [Roles and Responsibilities   - Selecting feat...  \n",
       "4  [Job description Job Summary and Key Responsib...  \n",
       "5  [About Ganit Inc  Founded by senior industry e...  \n",
       "6  [Roles and Responsibilities  Must have strong ...  \n",
       "7  [This is an ideal role for an experienced cand...  \n",
       "8  [The Role General Position Definition This rol...  \n",
       "9  [Introduction As a Data Scientist at IBM, you ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=naukri_desc('https://www.naukri.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function opens the naukri home page and searches for 'Data Analyst' and 'Bangalore'\n",
    "\n",
    "def naukri_advance_filters(url):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--incognito')\n",
    "    driver=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    # 1. first get the webpage https://www.naukri.com/\n",
    "    driver.get(url)\n",
    "    \n",
    "    # 2. Enter “Data Scientist” in “Skill,Designations,Companies” field \n",
    "    job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    job_search.send_keys(\"Data Scientist\")\n",
    " \n",
    "    # 3. Then click the search button\n",
    "    search_buton=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_buton.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "    chk=driver.find_element_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[@for='chk-Delhi / NCR-cityTypeGid-']/i\")\n",
    "    chk.click()\n",
    "    time.sleep(2)\n",
    "    chk=driver.find_element_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[@for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
    "    chk.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 5. Then scrape the data for the first 10 jobs results you get.\n",
    "    job_titles=[]\n",
    "    title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "    for i in title_tags:\n",
    "        job_titles.append(i.text)\n",
    "    \n",
    "    company_names=[]\n",
    "    company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]\n",
    "    for i in company_tags:\n",
    "        company_names.append(i.text)\n",
    "        \n",
    "    experience_list=[]\n",
    "    exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")[:10]\n",
    "    for i in exp_tags:\n",
    "        experience_list.append(i.text)\n",
    "        \n",
    "    locations_list=[]\n",
    "    loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")[:10]\n",
    "    for i in loc_tags:\n",
    "        locations_list.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['Job Title']=job_titles\n",
    "    jobs['Company Name']=company_names\n",
    "    jobs['Location']=locations_list\n",
    "    jobs['Experience']=experience_list\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Developer - Data Science</td>\n",
       "      <td>ICL Systems India Private Limited</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>Ghaziabad, Faridabad, Delhi / NCR</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning (IS...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Max Bupa Health Insurance Company Limited</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                           Developer - Data Science   \n",
       "1  Data Scientist/Data Analyst - Python/Machine L...   \n",
       "2                                     Data Scientist   \n",
       "3         Data Scientist - Python & Machine Learning   \n",
       "4         Data Scientist - Python & Machine Learning   \n",
       "5  Data Scientist - Python / Machine Learning / T...   \n",
       "6         Data Scientist - Python & Machine Learning   \n",
       "7  Data Scientist - Python & Machine Learning (IS...   \n",
       "8  Data Scientist - Python / Machine Learning / T...   \n",
       "9                          Hiring For Data Scientist   \n",
       "\n",
       "                                Company Name  \\\n",
       "0          ICL Systems India Private Limited   \n",
       "1                             Change leaders   \n",
       "2                           Amity University   \n",
       "3                        FUTURES AND CAREERS   \n",
       "4                        FUTURES AND CAREERS   \n",
       "5                        FUTURES AND CAREERS   \n",
       "6                        FUTURES AND CAREERS   \n",
       "7                        FUTURES AND CAREERS   \n",
       "8                        FUTURES AND CAREERS   \n",
       "9  Max Bupa Health Insurance Company Limited   \n",
       "\n",
       "                                            Location Experience  \n",
       "0                                        Delhi / NCR    3-5 Yrs  \n",
       "1                                  Mumbai, Ghaziabad   5-10 Yrs  \n",
       "2                  Ghaziabad, Faridabad, Delhi / NCR    6-8 Yrs  \n",
       "3  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...    2-7 Yrs  \n",
       "4  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...    2-7 Yrs  \n",
       "5  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...    3-8 Yrs  \n",
       "6  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...    2-7 Yrs  \n",
       "7  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...    3-8 Yrs  \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...    3-8 Yrs  \n",
       "9                      Gurgaon/Gurugram, Delhi / NCR    1-6 Yrs  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=naukri_advance_filters('https://www.naukri.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def glassdoor(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Sign in Option\n",
    "    sign_in=driver.find_element_by_xpath(\"//div[@class='locked-home-sign-in']/a\")\n",
    "    url=sign_in.get_attribute('href')\n",
    "    driver_2=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    driver_2.get(url)\n",
    "    time.sleep(2)\n",
    "    email=driver_2.find_element_by_id('userEmail')\n",
    "    email.send_keys('sarangkatre@gmail.com')\n",
    "    passw=driver_2.find_element_by_id('userPassword')\n",
    "    passw.send_keys('Sarang@123')\n",
    "    sign_in_button=driver_2.find_element_by_xpath(\"//div/button[@class='gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "    sign_in_button.click()\n",
    "    time.sleep(2)\n",
    "    driver.close()\n",
    "    \n",
    "    # searching required fields\n",
    "    job_search=driver_2.find_element_by_id('sc.keyword')\n",
    "    job_search.send_keys('Data Scientist')\n",
    "    \n",
    "    location=driver_2.find_element_by_id('sc.location')\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    location.send_keys(Keys.CONTROL + \"a\")\n",
    "    location.send_keys(Keys.DELETE)\n",
    "    location.send_keys('Noida')\n",
    "    \n",
    "    search_button=driver_2.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "    search_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    company_name=[]\n",
    "    days_posted=[]\n",
    "    rating=[]\n",
    "    \n",
    "    # Company and days posted are available but for ratings need to open in new window.\n",
    "    # Opening new window\n",
    "    \n",
    "    from selenium.common.exceptions import NoSuchElementException         # Importing Exception\n",
    "    new_page=driver_2.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a\")[:10]\n",
    "    \n",
    "    for i in new_page:\n",
    "        url=i.get_attribute('href')\n",
    "        driver_3=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        driver_3.get(url)\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            a=driver_3.find_element_by_xpath(\"//span[@class='css-1pmc6te e11nt52q4']\")\n",
    "            rating.append(a.text.replace('\\n★',''))\n",
    "        except NoSuchElementException as e:\n",
    "            rating.append(\"No Rating\")\n",
    "        driver_3.close() \n",
    "       \n",
    "    comps=driver_2.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a/span\")[:10]\n",
    "    for i in comps:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "    days=driver_2.find_elements_by_xpath(\"//div[@data-test='job-age']\")[:10]\n",
    "    for i in days:\n",
    "        days_posted.append(i.text)\n",
    "         \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['Company Name']=company_name\n",
    "    jobs['Days Since Posted']=days_posted\n",
    "    jobs['Rating']=rating\n",
    "    \n",
    "    driver_2.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Days Since Posted</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Randstad</td>\n",
       "      <td>14d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIEL HR Services</td>\n",
       "      <td>15d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Darshan Soft-Tech</td>\n",
       "      <td>23d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Service industry for Pharmaceuticals company</td>\n",
       "      <td>23d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kreate Konnect E Solutions Pvt Ltd</td>\n",
       "      <td>24d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99Plus IT Solutions</td>\n",
       "      <td>23d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edubooks Solutions Pvt Ltd</td>\n",
       "      <td>1d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stemmons Business Services</td>\n",
       "      <td>24d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Engineering manufacturing company</td>\n",
       "      <td>23d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K.T.Automation (India)</td>\n",
       "      <td>20d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Company Name Days Since Posted     rating\n",
       "0                                      Randstad               14d        3.8\n",
       "1                              CIEL HR Services               15d        4.3\n",
       "2                             Darshan Soft-Tech               23d        4.2\n",
       "3  Service industry for Pharmaceuticals company               23d  No Rating\n",
       "4            Kreate Konnect E Solutions Pvt Ltd               24d  No Rating\n",
       "5                           99Plus IT Solutions               23d  No Rating\n",
       "6                    Edubooks Solutions Pvt Ltd                1d  No Rating\n",
       "7                    Stemmons Business Services               24d        3.3\n",
       "8             Engineering manufacturing company               23d        3.1\n",
       "9                        K.T.Automation (India)               20d  No Rating"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=glassdoor('https://www.glassdoor.co.in/index.htm')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 5 Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glassdoor_2(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "     \n",
    "    # searching required fields\n",
    "    job_search=driver.find_element_by_id('KeywordSearch')\n",
    "    job_search.send_keys('Data Scientist')\n",
    "    \n",
    "    location=driver.find_element_by_id('LocationSearch')\n",
    "    location.clear()\n",
    "    location.send_keys('Noida')\n",
    "        \n",
    "    search_buton=driver.find_element_by_id(\"HeroSearchButton\")\n",
    "    search_buton.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    comp=[]\n",
    "    number_of_salaries=[]\n",
    "    avg_salary=[]\n",
    "    min_salary=[]\n",
    "    max_salary=[]\n",
    "    \n",
    "    a=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")[:10]\n",
    "    for i in a:\n",
    "        comp.append(i.text)\n",
    "        \n",
    "    b=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")[:10]\n",
    "    for i in b:\n",
    "        number_of_salaries.append(i.text.replace(' salaries',''))\n",
    "        \n",
    "    c=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")[:10]\n",
    "    for i in c:\n",
    "        avg_salary.append(i.text)\n",
    "        \n",
    "    d=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\")[:10]\n",
    "    for i in d:\n",
    "        min_salary.append(i.text)\n",
    "        \n",
    "    e=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")[:10]\n",
    "    for i in e:\n",
    "        max_salary.append(i.text)\n",
    "         \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['company_names']=comp\n",
    "    jobs['number_of_salaries']=number_of_salaries\n",
    "    jobs['avg_salary']=avg_salary\n",
    "    jobs['min_salary']=min_salary\n",
    "    jobs['max_salary']=max_salary\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_names</th>\n",
       "      <th>number_of_salaries</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>14</td>\n",
       "      <td>₹ 6,01,000</td>\n",
       "      <td>₹336L</td>\n",
       "      <td>₹1,080L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14</td>\n",
       "      <td>₹ 11,51,207</td>\n",
       "      <td>₹579L</td>\n",
       "      <td>₹2,222L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14</td>\n",
       "      <td>₹ 12,34,207</td>\n",
       "      <td>₹452L</td>\n",
       "      <td>₹11,669L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>13</td>\n",
       "      <td>₹ 7,63,825</td>\n",
       "      <td>₹589L</td>\n",
       "      <td>₹2,741L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>12</td>\n",
       "      <td>₹ 7,32,209</td>\n",
       "      <td>₹350L</td>\n",
       "      <td>₹1,619L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>10</td>\n",
       "      <td>₹ 13,88,910</td>\n",
       "      <td>₹1,050L</td>\n",
       "      <td>₹1,500L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9</td>\n",
       "      <td>₹ 8,18,515</td>\n",
       "      <td>₹504L</td>\n",
       "      <td>₹1,471L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8</td>\n",
       "      <td>₹ 12,01,403</td>\n",
       "      <td>₹623L</td>\n",
       "      <td>₹1,702L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 10,00,000</td>\n",
       "      <td>₹203L</td>\n",
       "      <td>₹1,817L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 11,90,000</td>\n",
       "      <td>₹578L</td>\n",
       "      <td>₹1,500L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company_names number_of_salaries   avg_salary min_salary  \\\n",
       "0  Tata Consultancy Services                 14   ₹ 6,01,000      ₹336L   \n",
       "1                  Accenture                 14  ₹ 11,51,207      ₹579L   \n",
       "2                  Delhivery                 14  ₹ 12,34,207      ₹452L   \n",
       "3                        IBM                 13   ₹ 7,63,825      ₹589L   \n",
       "4         Ericsson-Worldwide                 12   ₹ 7,32,209      ₹350L   \n",
       "5         UnitedHealth Group                 10  ₹ 13,88,910    ₹1,050L   \n",
       "6         Valiance Solutions                  9   ₹ 8,18,515      ₹504L   \n",
       "7                 Innovaccer                  8  ₹ 12,01,403      ₹623L   \n",
       "8              ZS Associates                  7  ₹ 10,00,000      ₹203L   \n",
       "9                EXL Service                  7  ₹ 11,90,000      ₹578L   \n",
       "\n",
       "  max_salary  \n",
       "0    ₹1,080L  \n",
       "1    ₹2,222L  \n",
       "2   ₹11,669L  \n",
       "3    ₹2,741L  \n",
       "4    ₹1,619L  \n",
       "5    ₹1,500L  \n",
       "6    ₹1,471L  \n",
       "7    ₹1,702L  \n",
       "8    ₹1,817L  \n",
       "9    ₹1,500L  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=glassdoor_2('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sunglasses')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['Brand']=brand\n",
    "    jobs['Description']=des\n",
    "    jobs['Price']=price\n",
    "    jobs['Discount']=discount\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    driver_3.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Wayfarer Su...</td>\n",
       "      <td>₹574</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Wayfarer, Round Sungla...</td>\n",
       "      <td>₹764</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹666</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Riding Glasses Wayfarer Sunglas...</td>\n",
       "      <td>₹262</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Size)</td>\n",
       "      <td>₹865</td>\n",
       "      <td>3% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹426</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Others Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,027</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹211</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                                des   price  \\\n",
       "0           Aislin  UV Protection, Gradient Butterfly, Wayfarer Su...    ₹574   \n",
       "1           Aislin  UV Protection, Gradient Wayfarer, Round Sungla...    ₹764   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹758   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹666   \n",
       "4         Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...    ₹499   \n",
       "..             ...                                                ...     ...   \n",
       "95           NuVew  UV Protection, Riding Glasses Wayfarer Sunglas...    ₹262   \n",
       "96        Fastrack   UV Protection Wrap-around Sunglasses (Free Size)    ₹865   \n",
       "97  ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...    ₹426   \n",
       "98          Aislin      UV Protection, Others Aviator Sunglasses (58)  ₹1,027   \n",
       "99         DEIXELS   UV Protection Rectangular Sunglasses (Free Size)    ₹211   \n",
       "\n",
       "   discount  \n",
       "0   62% off  \n",
       "1   76% off  \n",
       "2   15% off  \n",
       "3   16% off  \n",
       "4   50% off  \n",
       "..      ...  \n",
       "95  73% off  \n",
       "96   3% off  \n",
       "97  84% off  \n",
       "98  72% off  \n",
       "99  85% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_reviews(url):\n",
    "\n",
    "    driver_1 = webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    driver_1.get(url)\n",
    "    \n",
    "    # Opening full reviews\n",
    "    full=driver_1.find_element_by_xpath(\"//div[@class='col JOpGWq']/a\")\n",
    "    driver=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    url=full.get_attribute('href')\n",
    "    driver.get(url)\n",
    "    driver_1.close()\n",
    "       \n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    def extract(driver):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for i in a:\n",
    "            rating.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for i in a:\n",
    "            review_summary.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "        for i in a:\n",
    "            full_review.append(i.text)\n",
    "    \n",
    "    while(len(full_review)<10):\n",
    "        extract(driver)\n",
    "        \n",
    "    while(len(full_review)<100):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver.get(url)\n",
    "        extract(driver)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['Rating']=rating\n",
    "    jobs['Review Summary']=review_summary\n",
    "    jobs['Full Review']=full_review\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s an amazing product from apple and the cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Upgraded from iphone 6 to 11 best phone for ip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>This will help you more. See if you are planni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating         review_summary  \\\n",
       "0       5              Brilliant   \n",
       "1       5       Perfect product!   \n",
       "2       5      Worth every penny   \n",
       "3       5          Great product   \n",
       "4       5     Highly recommended   \n",
       "..    ...                    ...   \n",
       "95      5              Brilliant   \n",
       "96      5              Must buy!   \n",
       "97      5              Wonderful   \n",
       "98      5      Terrific purchase   \n",
       "99      5  Mind-blowing purchase   \n",
       "\n",
       "                                          full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "4   iphone 11 is a very good phone to buy only if ...  \n",
       "..                                                ...  \n",
       "95  I have migrated from OP 7pro... and trust me, ...  \n",
       "96  It’s an amazing product from apple and the cam...  \n",
       "97  This is my first ever I phone. Before this I w...  \n",
       "98  Upgraded from iphone 6 to 11 best phone for ip...  \n",
       "99  This will help you more. See if you are planni...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_reviews('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100_sneakers(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sneakers')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['Brand']=brand\n",
    "    jobs['Description']=des\n",
    "    jobs['Price']=price\n",
    "    jobs['Discount']=discount\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    driver_3.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹404</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 3 Casual Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Edoeviv</td>\n",
       "      <td>Sneakers For Men  (White 8) Sneakers For Men</td>\n",
       "      <td>₹464</td>\n",
       "      <td>41% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Rigel IDP Sneakers For Men</td>\n",
       "      <td>₹1,287</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wika</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           brand                                                des   price  \\\n",
       "0       Magnolia                                   Sneakers For Men    ₹404   \n",
       "1         BRUTON            Combo Pack Of 3 Casual Sneakers For Men    ₹499   \n",
       "2         Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...    ₹499   \n",
       "3         Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹474   \n",
       "4   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men    ₹399   \n",
       "..           ...                                                ...     ...   \n",
       "95       Edoeviv       Sneakers For Men  (White 8) Sneakers For Men    ₹464   \n",
       "96  Robbie jones                                   Sneakers For Men    ₹499   \n",
       "97          PUMA                         Rigel IDP Sneakers For Men  ₹1,287   \n",
       "98          Wika                                   Sneakers For Men    ₹449   \n",
       "99        BRUTON            Combo Pack Of 4 Casual Sneakers For Men    ₹474   \n",
       "\n",
       "   discount  \n",
       "0   73% off  \n",
       "1   80% off  \n",
       "2   72% off  \n",
       "3   76% off  \n",
       "4   60% off  \n",
       "..      ...  \n",
       "95  41% off  \n",
       "96  50% off  \n",
       "97  54% off  \n",
       "98  55% off  \n",
       "99  88% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100_sneakers('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myntra(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Adding required filters\n",
    "    # [Actual Value for this search = Rs. 7649 to Rs. 15099]\n",
    "    price=driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "    price.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    color=driver.find_element_by_xpath(\"//li[@class='colour-listItem']/label/div\")\n",
    "    color.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    \n",
    "    def extract_2(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/div/span[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "    \n",
    "    while(len(price)<50):\n",
    "        extract_2(driver,50)\n",
    "        \n",
    "    while(len(price)<100):\n",
    "        next=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "        driver_2=webdriver.Chrome(r\"C:\\\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract_2(driver_2,50) \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['Brand']=brand\n",
    "    jobs['Description']=des\n",
    "    jobs['Price']=price\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 10796Rs. 13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER Running Shoes</td>\n",
       "      <td>Rs. 8796Rs. 10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running</td>\n",
       "      <td>Rs. 10796Rs. 13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 7796Rs. 11995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 7496Rs. 9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Derbys</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Textured Leather Monks</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Textured Oxfords</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Women Black Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Breathe OIL SLK</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           brand                            des               price\n",
       "0           Nike     Men AIR ZOOM Running Shoes  Rs. 10796Rs. 13495\n",
       "1           Nike  Men REACT MILER Running Shoes   Rs. 8796Rs. 10995\n",
       "2           Nike         Women AIR ZOOM Running  Rs. 10796Rs. 13495\n",
       "3           Nike            Women Running Shoes   Rs. 7796Rs. 11995\n",
       "4           Nike   Women AIR ZOOM Running Shoes    Rs. 7496Rs. 9995\n",
       "..           ...                            ...                 ...\n",
       "95  Hush Puppies             Men Leather Derbys            Rs. 7999\n",
       "96         Ruosh     Men Textured Leather Monks            Rs. 6990\n",
       "97  Hush Puppies           Men Textured Oxfords            Rs. 6999\n",
       "98       Bugatti           Women Black Sneakers            Rs. 7999\n",
       "99  UNDER ARMOUR  Women Charged Breathe OIL SLK            Rs. 8999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=myntra('https://www.myntra.com/shoes')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
